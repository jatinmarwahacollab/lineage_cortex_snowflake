{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false,
    "resultHeight": 110
   },
   "source": "from snowflake.snowpark.session import Session\nfrom snowflake.snowpark.functions import call_builtin\nimport json\nimport re\nimport logging\n\n# Configure logging for better debugging and visibility\nlogging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n\n# Get the active Snowpark session (in a Snowflake notebook, the session is usually already available)\nsession = Session.builder.getOrCreate()\n\ndef fetch_snowflake_data():\n    query = \"\"\"\n    WITH OBJECTS_VIEW AS (\n    SELECT \n        query_start_time,\n        query_id,\n        objects_modified,\n        f.value:objectName::STRING AS object_name,\n        f.value:objectDomain::STRING AS object_domain,\n        f.value:objectDomain::STRING AS object_type,\n        f.value:objectId::NUMBER AS object_id,\n        c.value:columnName::STRING AS column_name,\n        c.value:columnId::NUMBER AS column_id,\n        d.value:columnName::STRING AS direct_source_column,\n        d.value:objectName::STRING AS direct_source_table,\n        d.value:objectDomain::STRING AS direct_source_type,\n        rank() over (PARTITION by object_name order by query_start_time desc) as rnk\n\n    FROM snowflake.account_usage.access_history,\n    LATERAL FLATTEN(input => objects_modified) f,\n    LATERAL FLATTEN(input => f.value:columns) c,\n    LATERAL FLATTEN(input => c.value:directSources,OUTER => TRUE) d\n    )\n    \n    SELECT DISTINCT \n        ov.object_name,\n        ov.column_name,\n        ov.direct_source_table,\n        ov.direct_source_column,\n        ov.direct_source_type,\n        q.query_text,\n    FROM OBJECTS_VIEW ov\n    LEFT OUTER JOIN snowflake.account_usage.query_history AS q ON ov.query_id = q.query_id\n    WHERE schema_name = 'DBT_JMARWAHA'\n    and OBJECT_NAME IN ('JAFFLE_SHOP.DBT_JMARWAHA.CUSTOMERS','JAFFLE_SHOP.DBT_JMARWAHA.LOCATIONS','JAFFLE_SHOP.DBT_JMARWAHA.ORDERS','JAFFLE_SHOP.DBT_JMARWAHA.ORDER_ITEMS','JAFFLE_SHOP.DBT_JMARWAHA.SUPPLIES','JAFFLE_SHOP.DBT_JMARWAHA.PRODUCTS')\n    and ov.rnk = 1\n\n    ORDER BY ov.column_name\n    \"\"\"\n    return session.sql(query).collect()\ntable_defination = fetch_snowflake_data()\n#print(table_defination[0])\nprint(len(table_defination))\n\n\n\ndef extract_col_lineage_from_table(table_defination):\n        table_defination=table_defination.as_dict()\n        object_name=table_defination[\"OBJECT_NAME\"]\n        column_name=table_defination[\"COLUMN_NAME\"]\n        direct_source_table=table_defination[\"DIRECT_SOURCE_TABLE\"]\n        direct_source_column=table_defination[\"DIRECT_SOURCE_COLUMN\"]\n        direct_source_type=table_defination[\"DIRECT_SOURCE_TYPE\"]\n        query_text=table_defination[\"QUERY_TEXT\"]\n    \n        \n        prompt = f\"\"\"You are an expert in SQL lineage analysis.        \n        Analyze the following data provided.\n        Provide the very short and to the point and in business-friendly language transformation logic or reasoning between the source column and the target column based on the query text.        \n        Additionally Provide the output in 100 characters or less without any unnecessary information about the task.\n        \n        OBJECT_NAME : {object_name}\n        COLUMN_NAME : {column_name}\n        DIRECT_SOURCE_TABLE : {direct_source_table}\n        DIRECT_SOURCE_COLUMN : {direct_source_column}\n        DIRECT_SOURCE_TYPE : {direct_source_type}\n        QUERY_TEXT : {query_text}\n\n        \"\"\"\n        prompt = prompt.replace(\"'\", \"''\")\n\n    \n        # Call the Cortex LLM using the SNOWFLAKE.CORTEX.COMPLETE function\n        try:\n            lineage_response_df = session.sql(f\"\"\"\n            SELECT SNOWFLAKE.CORTEX.COMPLETE(\n            'llama3.1-405b',\n            '{prompt}'\n            ) AS LINEAGE_RESPONSE\n            \"\"\")\n        \n            \n            lineage_response_row = lineage_response_df.collect()[0]\n            lineage_response = lineage_response_row['LINEAGE_RESPONSE']\n        except Exception as e:\n            lineage_response=\"error\"\n            logging.error(f\"Error calling Cortex LLM: {e}\")\n            print(e)\n        return object_name,column_name,direct_source_table,direct_source_column,direct_source_type,query_text,lineage_response\n\n        \n        \noutput_list = []\nfor table in table_defination:\n    output = extract_col_lineage_from_table(table)\n    output_list.append(output)\n        \n    \n        \n#print(output_list)\ncolumns = ['object_name','column_name','direct_source_table','direct_source_column','direct_source_type','query_text','reasoning']\n\n\ninsert_df_table = session.create_dataframe(output_list,schema=columns)\ninsert_df_table.write.save_as_table(\"FINAL_LINEAGE_SNOWFLAKE_TABLE_NEW\",mode=\"overwrite\")\nprint(\"table is successfully created\")\n\n\n\n    \n       \n\n\n\n\n\n\n        \n\n        \n       \n    \n\n\n    \n    ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2",
    "codeCollapsed": false
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  }
 ]
}